\chapter{Sistemi lineari}
\section{Introduzione}
I sistemi lineari non sono un argomento nuovo, ma sono una parte integrante del corso, quindi vale la pena riprendere l'argomento dall'inizio per stabilire una base comune.
\begin{newdef}{Sistema lineare}
    Un \textbf{sistema lineare} è un sistema di $n$ equazioni in $m$ incognite in cui il massimo grado presente è il primo.
    \[
        \begin{cases}
            a_{11}x_{1} + \dots + a_{1m}x_{m} = b_1 \\
            a_{21}x_{1} + \dots + a_{2m}x_{m} = b_2 \\
            \vdots \quad\quad \vdots \quad\quad \vdots \quad\quad \vdots \quad\quad \vdots \\
            a_{n1}x_{1} + \dots + a_{nm}x_{m} = b_n \\  
        \end{cases}
    \]
    $x_1, \dots, x_n$ sono le \textit{incognite}, $a_{11}, \dots, a_{nm}$ sono i \textit{coefficienti} e $b_1, \dots, b_n$ sono i \textit{termini noti}.
\end{newdef}

\begin{center}
    $x + y = 3$ è lineare \hspace{2cm} $xy + z = 3$ non è lineare \hspace{2cm} $y^2 + x = 0$ non è lineare \hspace{2cm} $e^x + 4y = 7$ non è lineare
\end{center}

\begin{newdef}{Sistema lineare omogeneo}
    Un sistema lineare è detto \textbf{omogeneo} se $b_1 = \dots = b_n = 0$, ovvero se è nella forma:
    \[
        \begin{cases}
            a_{11}x_{1} + \dots + a_{1m}x_{m} = 0 \\
            a_{21}x_{1} + \dots + a_{2m}x_{m} = 0 \\
            \vdots \quad\quad \vdots \quad\quad \vdots \quad\quad \vdots \quad\quad \vdots \\
            a_{n1}x_{1} + \dots + a_{nm}x_{m} = 0 \\  
        \end{cases}
    \]
\end{newdef}

La particolarità dei sistemi lineari è che un insieme di valori, per essere soluzione, deve soddisfare \textbf{\textit{contemporaneamente}} tutte e $n$ le equazioni.

\begin{newdef}{Soluzione di un sistema lineare}
    Una \textbf{soluzione} di un sistema lineare è un insieme $\{s_1, \dots, s_m\}$ di $m$ valori che, quando si pone $s_1 = x_1; \dots; s_m = x_m$, tutte le $n$ equazioni sono vere.

    Un sistema lineare può avere 0, 1 o infinite soluzioni.
\end{newdef}

\section{Metodi di risoluzione}
\subsection{Metodo per sostituzione}
Si saranno già imparati diversi modi di risolvere sistemi di equazioni lineari. Si prenda per esempio il semplice sistema lineare:
\[
    \begin{cases}
        5x + 4y = -7 \\
        5x + 2y = -4
    \end{cases}
\]
Il metodo più basilare è quello per sostituzione, che con sistemi come questo è ammissibile, ma molto inefficace per sistemi con più variabili. Per risolvere un sistema lineare con questo metodo si riscrive una variabile in funzione delle altre e si cerca di semplificare man mano le equazioni fino a trovare il valore di una delle variabili e trovare di conseguenza quello delle altre. In pratica:
\[
    \begin{cases}
        5x + 4y = -7 \\
        5x = -4 - 2y
    \end{cases}
    \rightarrow
    \begin{cases}
        -4 - 2y + 4y = -7 \rightarrow 2y = -3\\
        5x = -4 - 2y \rightarrow x = -\frac{4}{5} - \frac{2}{5}y
    \end{cases}
\]
\[
    \begin{cases}
        y = -\frac{3}{2} \\
        x = -\frac{1}{5}
    \end{cases}
\]

\begin{exer}
    \textbf{Risolvere con il metodo di sostituzione i seguenti sistemi lineari:}

    $
        \begin{cases}
            6x + 3y = -6 \\
            4x + 6y = 6
        \end{cases}
    $;

    $
        \begin{cases}
            3x + 6y = 3 \\
            3x + 2y = -7
        \end{cases}
    $;

    $
        \begin{cases}
            12x - 6y = 6 \\
            3x + 12y = -2
        \end{cases}
    $;
\end{exer}

\subsection{Metodo di riduzione}

Un metodo generalmente preferibile è il metodo di riduzione. In sostanza si stratta di risolvere il sistema eliminando man mano le incognite dalle altre equazioni sfruttando il \textbf{principio di equivalenza dei sistemi lineari}.

Per rendere più chiare le idee: il primo principio di equivalenza dice che:
\[
    \text{Se } A = B \text{ allora } A + C = B + C
\]
Si prenda allora il seguente sistema di equazioni:
\[
    \begin{cases}
        \dots \\
        A = B \\
        C = D \\
        \dots
    \end{cases}
\]
Se $C = D$ allora $C$ e $D$ sono la stessa quantità, e perciò se $A = B$ è vero lo è anche $A + C = B + D$. Quindi si può sostituire ad $A = B$ la seconda equazione:
\[
    \begin{cases}
        \dots \\
        A + C = B + D \\
        C = D \\
        \dots
    \end{cases}
\]
Inoltre, per il secondo principio di equivalenza:
\[
    \text{Se } A = B \text{ allora } \alpha A = \alpha B
\]
Da cui si può dedurre che se $C = D$ allora $\beta C = \beta D$, e perciò, per lo stesso ragionamento di prima, si può dire che:
\[
    \begin{cases}
        \dots \\
        A + \beta C = B + \beta D \\
        C = D \\
        \dots
    \end{cases}
\]
\begin{nb}
    Non si può sostituire una qualsiasi equazione con la nuova equazione ricavata: si possono solo sostituire $A = B$ o $C = D$.
\end{nb}

Questa proprietà può essere sfruttata per \textit{eliminare} un'incognita per volta dalle equazioni, per arrivare poi a trovare il valore di una delle incognite e, di conseguenza, trovare quello delle altre.

Si prenda, a titolo d'esempio, il seguente sistema lineare di 3 equazioni e 3 incognite:
\[
    \begin{cases}
        4x + 3y + 6z = 2 \\
        x + 6y + 4z = 5 \\
        3x + 6y + 4z = -2
    \end{cases}
\]
Come abbiamo detto l'obiettivo è eliminare, una per una, tutte le incognite tranne una, di cui rimarrà semplicemente il valore.

La cosa più sensata da fare è sostituire alla seconda (o alla terza) equazione la differenza tra la seconda e la terza equazione, in quanto hanno entrambi gli stessi coefficienti per $y$ e $z$.
\[
    \begin{array}{c c c c}
        x & 6y & 4z & 5 \\
        -3x & -6y & -4z & 2 \\
        \hline
        -2x & 0 & 0 & 7
    \end{array}
\]
\[
    -2x = 7 \rightarrow x = -\frac{7}{2}
\]
Facendo un po' di ordine e sostituendo $x$ nelle altre due equazioni si ottiene il seguente sistema lineare:
\[
    \begin{cases}
        x = -\frac{7}{2} \\
        3y + 6z = 16 \\
        6y + 4z = \frac{17}{2}
    \end{cases}
\]
A questo punto, per eliminare $y$, si può sostituire alla terza equazione la differenza tra due volte la seconda equazione e la terza equazione:
\[
    \begin{array}{c c c}
        6y & 12z &32 \\
        -6y & -4z & -\frac{17}{2} \\
        \hline
        0 & 8z & \frac{47}{2}
    \end{array}
\]
\[
    8z = \frac{47}{2} \rightarrow z = \frac{47}{16}
\]
Quindi il nuovo sistema lineare è:
\[
    \begin{cases}
        x = -\frac{7}{2} \\
        3y + 6z = 16 \\
        z = \frac{47}{16}
    \end{cases}
\]
A questo punto trovare $y$ è banale:
\[
    3y + 3 \cdot \frac{47}{8} = 16 \rightarrow y + \frac{47}{8} = \frac{16}{3} \rightarrow y = -\frac{13}{24}
\]
\[
    \begin{cases}
        x = -\frac{7}{2} \\
        y = -\frac{13}{24} \\
        z = \frac{47}{16}
    \end{cases}
\]

\begin{exer}
    \text{Risolvere con il metodo di riduzione i seguenti sistemi lineari:}
    
    $
        \begin{cases}
            2x + 2y + 7z = 6 \\
            7x + 6y + z = 4 \\
            4x + 2y + 2z = -2
        \end{cases}
    $;

    $
        \begin{cases}
            x + 7y + 2z = 2 \\
            3x + 4y + 6z = -4 \\
            2x + 6y + 2z = 6
        \end{cases}
    $;

    $
        \begin{cases}
            6x + 6y + 7z = 6 \\
            6x + 6y + 6z = 2 \\
            4x + y + 6z = 6
        \end{cases}
    $;
\end{exer}

Esistono altri metodi di risoluzione, che però per la maggior parte verranno ignorati. L'altro metodo che verrà esplorato più avanti, nella parte astratta, è il metodo di Cramer.

\section{Sistemi come matrici e vettori}
Riprendendo il discorso teorico sui sistemi lineari, questi si possono rappresentare tramite matrici e vettori.
\begin{newdef}{Rappresentazione matriciale dei sistemi lineari}
    Un sistema lineare generico può essere rappresentato come:
    \[
        A\textbf{x} = \textbf{b}
    \]
    dove $A$ è la matrice dei coefficienti:
    \[
        A =
        \begin{sqmatrix}{c c c c}
            a_{11} & a_{12} & \dots & a_{1m} \\
            a_{21} & a_{22} & \dots & a_{2m} \\
            \vdots & \vdots & \ddots & \vdots \\
            a_{n1} & a_{n2} & \dots & a_{nm} \\
        \end{sqmatrix}
    \]
    \textbf{x} è il vettore delle incognite:
    \[
        \textbf{x} =
        \begin{sqcolvec}
            x_1 \\
            x_2 \\
            \vdots \\
            x_m
        \end{sqcolvec}
    \]
    E \textbf{b} è il vettore dei termini noti:
    \[
        \textbf{b} =
        \begin{sqcolvec}
            b_1 \\
            b_2 \\
            \vdots \\
            b_n
        \end{sqcolvec}
    \]
\end{newdef}

Quindi, nel caso particolare del sistema lineare:
\[
    \begin{cases}
        4x + 3y + 6z = 2 \\
        x + 6y + 4z = 5 \\
        3x + 6y + 4z = -2
    \end{cases}
\]
Questo diventerebbe:
\[
    \begin{sqmatrix}{c c c}
        4 & 3 & 6 \\
        1 & 6 & 4 \\
        3 & 6 & 4
    \end{sqmatrix}
    \begin{sqcolvec}
        x \\
        y \\
        z
    \end{sqcolvec}
    =
    \begin{sqcolvec}
        2 \\
        5 \\
        -2
    \end{sqcolvec}
\]
Da qui si può vedere il motivo della definizione di prodotto riga per colonna data all'inizio. Infatti, svolgendolo, si riottengono le equazioni del sistema iniziale:
\[
    \begin{sqmatrix}{c c c}
        4 & 3 & 6 \\
        1 & 6 & 4 \\
        3 & 6 & 4
    \end{sqmatrix}
    \begin{sqcolvec}
        x \\
        y \\
        z
    \end{sqcolvec}
    =
    \begin{sqcolvec}
        4x + 3y + 6z \\
        x + 6y + 4z \\
        3x + 6y + 4z
    \end{sqcolvec}
\]

\begin{newdef}{Matrice completa di un sistema lineare}
    Dato un certo sistema lineare, la \textbf{matrice completa} del sistema è la matrice dei coefficienti a cui viene affiancato il vettore colonna dei termini noti.
    \[
        (A|\textbf{b}) =
        \begin{sqmatrix}{c c c c c}
            a_{11} & a_{12} & \dots & a_{1m} & b_{1} \\
            a_{21} & a_{22} & \dots & a_{2m} & b_{2} \\
            \vdots & \vdots & \ddots & \vdots & \vdots \\
            a_{n1} & a_{n2} & \dots & a_{nm} & b_{n}\\
        \end{sqmatrix}
    \]
\end{newdef}

\section{Metodo di Eliminazione di Gauss (MEG)}
\subsection{Le operazioni elementari di riga}
Con questa nuova rappresentazione è possibile definire azioni che non cambiano l'insieme delle soluzioni di un sistema lineare anche sulle matrici. Queste azioni sono dette \textbf{operazioni elementari di riga}.
\begin{newdef}{Operazioni elementari di riga}
    Le \textbf{operazioni elementari di riga} sono operazioni fatte sulle righe che non cambiano l'insieme delle soluzioni del sistema lineare associato. Sono:
    \begin{enumerate}
        \item \textbf{Scambio} di due righe;
        \item \textbf{Prodotto con scalare} di una riga;
        \item \textbf{Somma tra multipli} di due righe.
    \end{enumerate}
    Per indicare lo svolgimento di queste operazioni si utilizza il simbolo $\sim$.
\end{newdef}

\subsection{Forma a gradini}
L'obiettivo del MEG è quello di portare la matrice completa del sistema una forma detta \text{a gradini}
\begin{newdef}{Matrice a gradini}
    Una matrice $n \times m$ è detta \textbf{a gradini} se il \textit{pivot} (primo elemento non nullo) di ogni riga è in una colonna più a destra di quello della riga precedente.
    \[
        \begin{sqmatrix}{c c c c c}
            * & * & * & * & * \\
            0 & * & * & * & * \\
            0 & 0 & * & * & * \\
            0 & 0 & 0 & * & *
        \end{sqmatrix}
    \]
\end{newdef}
\begin{nb}
    Non tutte le \textit{colonne} hanno necessariamente un pivot.
\end{nb}
Il motivo per cui si punta ad arrivare a una matrice a gradini è che questa corrisponde a un sistema ``ridotto'', ovvero in cui è stato applicato il metodo di riduzione in maniera completa. Per esempio:
\[
    \begin{sqmatrix}{c c c c c}
        7 & 3 & 1 & 4 & 3 \\
        0 & 9 & 1 & 5 & 0 \\
        0 & 0 & 3 & 1 & 10 \\
        0 & 0 & 0 & 5 & 2
    \end{sqmatrix}
    \text{ equivale a }
    \begin{cases}
        7x + 3y + z + 4w = 3 \\
        9y + z + 5w = 0 \\
        3z + w = 10 \\
        5w = 2
    \end{cases}
\]
A questo punto non resta che introdurre effettivamente il MEG:

\subsection{Metodo di Eliminazione di Gauss}
\begin{teo}{Metodo di Eliminazione di Gauss}
    Il \textbf{Metodo di Eliminazione di Gauss} è un metodo di riduzione di una matrice nella sua forma a gradini tramite operazioni elementari di riga. Il metodo è il seguente:
    \begin{enumerate}
        \item Attraverso lo scambio di righe, portare la matrice a non avere righe con pivot più a sinistra dei pivot delle righe precedenti, avendo cura di mettere eventuali righe nulle in fondo alla matrice;
        \item Individuare il pivot della riga in analisi (inizialmente la prima) ed eliminare attraverso la somma tra multipli di righe tutti gli elementi della colonna corrispondente sottostanti il pivot;
        \item Ripetere il processo per la riga successiva fino ad avere una matrice a gradini.
    \end{enumerate}
\end{teo}
Una volta ottenuta una matrice a gradini si può risolvere il sistema associato alla matrice sostituendo man mano i valori trovati.
\begin{esempio}
    \textbf{Risolvere il seguente sistema lineare usando il MEG:}
    \[
        \begin{cases}
            3x + 5y + 3z + 4w = 1 \\
            6x + 5y + 3z + 5w = -5 \\
            3x + 2y + 3z + 4w = 4 \\
            6x + 5y + 6z + 4w = 5
        \end{cases}
    \]
    Si inizia scrivendo la matrice completa del sistema:
    \[
        (A|\textbf{b}) =
        \begin{sqmatrix}{c c c c c}
            3 & 5 & 3 & 4 & 1 \\
            6 & 5 & 3 & 5 & -5 \\
            3 & 2 & 3 & 4 & 4 \\
            6 & 5 & 6 & 4 & 5
        \end{sqmatrix}
    \]
    Qui sotto verranno scritti i vari passaggi del MEG svolti:
    \begin{center}
        \begin{minipage}{.4\textwidth}
            \[
                \begin{sqmatrix}{c c c c c}
                    3 & 5 & 3 & 4 & 1 \\
                    0 & 5 & 3 & 3 & 7 \\
                    0 & 3 & 0 & 0 & -3 \\
                    0 & 5 & 0 & 4 & -3
                \end{sqmatrix}
            \]
        \end{minipage}
        \begin{minipage}{.4\textwidth}
            \[
                R_2 = 2R_1 - R_2
            \]
            \[
                R_3 = R_1 - R_3
            \]
            \[
                R_4 = 2R_1 - R_4
            \]
        \end{minipage}
    \end{center}
    \begin{center}
        \begin{minipage}{.4\textwidth}
            \[
                \begin{sqmatrix}{c c c c c}
                    3 & 5 & 3 & 4 & 1 \\
                    0 & 5 & 3 & 3 & 7 \\
                    0 & 0 & 3 & 3 & 12 \\
                    0 & 0 & 3 & -1 & 10
                \end{sqmatrix}
            \]
        \end{minipage}
        \begin{minipage}{.4\textwidth}
            \[
                R_3 = R_2 - \frac{5}{3}R_3
            \]
            \[
                R_4 = R_2 - R_4
            \]
        \end{minipage}
    \end{center}
    \begin{center}
        \begin{minipage}{.4\textwidth}
            \[
                \begin{sqmatrix}{c c c c c}
                    3 & 5 & 3 & 4 & 1 \\
                    0 & 5 & 3 & 3 & 7 \\
                    0 & 0 & 3 & 3 & 12 \\
                    0 & 0 & 0 & 4 & 2
                \end{sqmatrix}
            \]
        \end{minipage}
        \begin{minipage}{.4\textwidth}
            \[
                R_4 = R_3 - R_4
            \]
        \end{minipage}
    \end{center}
    Ora che la matrice è a gradini si può risolvere il sistema associato:
    \[
        \begin{cases}
            3x + 5y + 3z + 4w = 1 \\
            5y + 3z + 3w = 7 \\
            3z + 3w = 12 \\
            4w = 2 \rightarrow w = \frac{1}{2}
        \end{cases}
    \]
    \[
        3z + \frac{3}{2} = 12 \rightarrow z = \frac{7}{2}
    \]
    \[
        5y + \frac{21}{2} + \frac{3}{2} = 7 \rightarrow y = -1
    \]
    \[
        3x - 5 + \frac{21}{2} + 2 = 1 \rightarrow x = -\frac{13}{6}
    \]
    Il vettore soluzione sarà:
    \[
        \textbf{x} =
        \begin{sqcolvec}
            x \\
            y \\
            z \\
            w
        \end{sqcolvec}
        =
        \begin{sqcolvec}
            -\frac{13}{6} \\
            -1 \\
            \frac{7}{2} \\
            \frac{1}{2}
        \end{sqcolvec}
    \]
\end{esempio}
\begin{exer}
    \textbf{Risolvere i seguenti sistemi lineari con il MEG:}

    $
        \begin{cases}
            -4x + 10y - z = -6 \\
            -12x + 2y + 2z = -5 \\
            9x + 10y + 2z = 3
        \end{cases}
    $;

    $
        \begin{cases}
            -7x + 4y - 11z = 3 \\
            -6x - 2y + 2z = -1 \\
            5x - 4y - 11z = -5
        \end{cases}
    $;

    $
        \begin{cases}
            6x + 6y + 4z + 2w = -7 \\
            2x + 2y + 5z + 7w = -4 \\
            2x + 6y + 6z + 4w = 5 \\
            4v + 2w + 4z + 4w = -7
        \end{cases}
    $;
\end{exer}

\subsection{Forma a gradini ridotta}
Per completezza, soprattutto nei testi anglofoni, viene introdotta la cosiddetta \textit{reduced row-echelon form}, che verrà chiamata qui la \textbf{forma a gradini ridotta}.
\begin{newdef}{Forma a gradini ridotta}
    Una \textbf{matrice a gradini ridotta} è una matrice $n \times m$ a gradini in cui:
    \begin{itemize}
        \item I pivot valgono $1$;
        \item I pivot sono gli unici elementi della loro colonna.
    \end{itemize}
    \[
        \begin{sqmatrix}{c c c c c}
            1 & 0 & * & 0 & 0 \\
            0 & 1 & * & 0 & 0 \\
            0 & 0 & 0 & 1 & 0 \\
            0 & 0 & 0 & 0 & 1
        \end{sqmatrix}
    \]
    È spesso indicata con $\text{rref}\,A$.

    Esiste un'\textbf{unica} forma a gradini ridotta per ogni matrice e le operazioni elementari di riga non la cambiano.
\end{newdef}
\begin{nb}
    Molti software hanno la capacità di calcolare la forma a gradini ridotta delle matrici, quindi un ottimo modo per controllare se si è svolto il MEG correttamente è controllare tramite software che le due forme a gradini ridotte coincidano.
\end{nb}
La comodità della forma a gradini ridotta è che corrisponde, nella forma di sistema lineare, a un sistema in cui quasi tutte le variabili hanno il loro valore esplicitato.
\[
    \begin{sqmatrix}{c c c c c}
        1 & 0 & 0 & 0 & 3 \\
        0 & 1 & 0 & 0 & 9 \\
        0 & 0 & 1 & 0 & 4 \\
        0 & 0 & 0 & 1 & 5
    \end{sqmatrix}
    \text{ equivale a }
    \begin{cases}
        x = 3 \\
        y = 9 \\
        z = 4 \\
        t = 5
    \end{cases}
\]
L'algoritmo che utilizza le operazioni elementari di riga per portarsi nella forma a gradini ridotta si chiama \textbf{Metodo di Eliminazione di Gauss-Jordan}.

\section{Soluzioni di un sistema lineare}
È stato già introdotta la definizione di soluzione di un sistema lineare, ed è già stato detto che un sistema può avere solo 0, 1 o infinite soluzioni. Ora vale la pena approfondire il discorso delle soluzioni di un sistema lineare.

\subsection{Nessuna soluzione}
\begin{newdef}{Sistema impossibile}
    Un sistema $A\textbf{x} = \textbf{b}$ è detto \textbf{impossibile} se non esiste alcun vettore \textbf{s} che soddisfa il sistema.
\end{newdef}

Spesso questo risultato deriva da un'incoerenza tra due equazioni che sono fondamentalmente uguali i cui termini noti sono diversi.
\[
    \begin{cases}
        \dots \\
        \alpha x + \beta y = \gamma \\
        \alpha x + \beta y = \delta \\
        \dots
    \end{cases}
\]
Le due equazioni, all'inizio, possono anche non essere uguali (impedendo quindi di notare l'incongruenza), ma tramite il MEG si arriverà a una situazione del tipo:
\[
    \begin{sqmatrix}{c c c c c}
        \vdots & \vdots & \vdots & \vdots & \vdots \\
        \alpha a & \beta b & \gamma c & \delta d & \epsilon e \\
        \zeta a & \eta b & \iota c & \kappa d & \lambda f
    \end{sqmatrix}
\]
Ignorando i coefficienti, è facile notare che le due righe differiscono solo nell'ultima colonna, cosa che si traduce invariabilmente nella forma:
\[
    \begin{sqmatrix}{c c c c c}
        \vdots & \vdots & \vdots & \vdots & \vdots \\
        0 & 0 & 0 & 0 & *
    \end{sqmatrix}
\]
Che, nel sistema associato, equivale a dire $0 = *$, dove $*$ è un numero diverso da zero, che è un'equazione sempre falsa.
Perciò:
\begin{nb}
    Quando la forma a gradini della matrice completa ha un pivot in ultima colonna ciò vuol dire che il sistema associato è impossibile.
\end{nb}
\begin{esempio}
    \textbf{Risolvere il seguente sistema lineare:}
    \[
        \begin{cases}
            x + 2y - z + 3w = 5 \\
            2x - y + 4z - w = 6 \\
            3x + y + z + 2w = 7 \\
            7x + 4y + 3z + 7w = 30
        \end{cases}
    \]
    Si scrive la matrice completa del sistema:
    \[
        (A|\textbf{b}) =
        \begin{sqmatrix}{c c c c c}
            1 & 2 & -1 & 3 & 5 \\
            2 & -1 & 4 & -1 & 6 \\
            3 & 1 & 1 & 2 & 7 \\
            7 & 4 & 3 & 7 & 30
        \end{sqmatrix}
    \]
    Poi si applica il metodo di riduzione:
    \begin{center}
        \begin{minipage}{.4\textwidth}
            \[
                \begin{sqmatrix}{c c c c c}
                    1 & 2 & -1 & 3 & 5 \\
                    0 & 5 & -6 & 7 & 4 \\
                    0 & 5 & -4 & 7 & 8 \\
                    0 & 10 & -10 & 14 & 5
                \end{sqmatrix}
            \]
        \end{minipage}
        \begin{minipage}{.4\textwidth}
            \[
                R_2 = 2 \cdot R_1 - R_2
            \]
            \[
                R_3 = 3 \cdot R_1 - R_3
            \]
            \[
                R_4 = 7 \cdot R_1 - R_4
            \]
        \end{minipage}
    \end{center}
    \begin{center}
        \begin{minipage}{.4\textwidth}
            \[
                \begin{sqmatrix}{c c c c c}
                    1 & 2 & -1 & 3 & 5 \\
                    0 & 5 & -6 & 7 & 4 \\
                    0 & 0 & -2 & 0 & -4 \\
                    0 & 0 & -2 & 0 & 3
                \end{sqmatrix}
            \]
        \end{minipage}
        \begin{minipage}{.4\textwidth}
            \[
                R_3 = R_2 - R_3
            \]
            \[
                R_4 = 2 \cdot R_2 - R_4
            \]
        \end{minipage}
    \end{center}
    \begin{center}
        \begin{minipage}{.4\textwidth}
            \[
                \begin{sqmatrix}{c c c c c}
                    1 & 2 & -1 & 3 & 5 \\
                    0 & 5 & -6 & 7 & 4 \\
                    0 & 0 & -2 & 0 & -4 \\
                    0 & 0 & 0 & 0 & -7
                \end{sqmatrix}
            \]
        \end{minipage}
        \begin{minipage}{.4\textwidth}
            \[
                R_4 = R_3 - R_4
            \]
        \end{minipage}
    \end{center}
    Il sistema è \textbf{impossibile}. Infatti la matrice ottenuta corrisponderebbe al seguente sistema:
    \[
        \begin{cases}
            x + 2y - z + 3w = 5 \\
            5y - 6z + 7w = 4 \\
            -2z = -4 \\
            0 = -7
        \end{cases}
    \]
    Essendo l'ultima equazione sempre falsa, il sistema \textbf{non ha soluzione}.
\end{esempio}

\begin{teo}{Esistenza della soluzione di un sistema omogeneo}
    Ogni sistema sistema lineare omogeneo ha almeno una soluzione, ovvero $\textbf{s} = \vec 0$. In altre parole, non esiste alcun sistema lineare omogeneo impossibile.
\end{teo}
\begin{newdim}
    Si prenda il generico sistema lineare omogeneo:
    \[
        \begin{cases}
            a_{11}x_{1} + \dots + a_{1m}x_{m} = 0 \\
            a_{21}x_{1} + \dots + a_{2m}x_{m} = 0 \\
            \vdots \quad\quad \vdots \quad\quad \vdots \quad\quad \vdots \quad\quad \vdots \\
            a_{n1}x_{1} + \dots + a_{nm}x_{m} = 0 \\  
        \end{cases}
    \]
    In forma matriciale questo sistema diventa:
    \[
        (A|\textbf{b}) =
        \begin{sqmatrix}{c c c c c}
            a_{11} & a_{12} & \dots & a_{1m} & 0 \\
            a_{21} & a_{22} & \dots & a_{2m} & 0 \\
            \vdots & \vdots & \ddots & \vdots & \vdots \\
            a_{n1} & a_{n2} & \dots & a_{nm} & 0\\
        \end{sqmatrix}
    \]
    Utilizzando le operazioni elementari di riga, è impossibile avere un elemento non nullo in ultima colonna:
    \begin{itemize}
        \item \textbf{Scambio:} Lo scambio non cambia i valori dell'ultima colonna;
        \item \textbf{Prodotto con scalare:} Ogni prodotto che coinvolge lo 0 vale 0, quindi i valori dell'ultima colonna continuano a valere 0;
        \item \textbf{Somma tra multipli:} Come detto prima, i prodotti che coinvolgono lo 0 valgono 0, e la somma tra 0 vale 0.
    \end{itemize}
    Quindi la forma a gradini ridotta della matrice non avrà mai un pivot in ultima colonna, e quindi esisterà sempre una soluzione.

    Per dimostrare che $\vec 0$ è sempre soluzione di $A\textbf{x} = \vec 0$, basta fare la sostituzione $a_{11} = \dots = a_{nm} = 0$ e vedere che si ottiene:
    \[
        \begin{cases}
            0x_{1} + \dots + 0x_{m} = 0 \\
            0x_{1} + \dots + 0x_{m} = 0 \\
            \vdots \quad\quad \vdots \quad\quad \vdots \quad\quad \vdots \\
            0x_{1} + \dots + 0x_{m} = 0 \\  
        \end{cases}
        \rightarrow
        \begin{cases}
            0 = 0 \\
            \vdots \\
            0 = 0
        \end{cases}
    \]
    Che sono equazioni sempre vere. Perciò il sistema ha sempre almeno una soluzione, ovvero $\textbf{s} = \vec 0$.

    $\qedwhite$
\end{newdim}
\subsection{Una sola soluzione}
\begin{newdef}{Sistema determinato}
    Un sistema $A\textbf{x} = \textbf{b}$ è detto \textbf{determinato} se esiste un solo vettore \textbf{s} che soddisfa il sistema.
\end{newdef}
Perché un sistema lineare abbia una sola soluzione è necessario che ci siano almeno tante equazioni quante sono le incognite; nel caso in cui ce ne siano di più dev'essere possibile ridurre il sistema in un sistema con $n$ equazioni e $n$ incognite. Queste $n$ equazioni devono, naturalmente, aggiungere informazioni nuove e non devono essere sostanzialmente uguali ad una o più delle altre: questo concetto verrà approfondito quando si parlerà, nella parte astratta, di \textit{indipendenza lineare}.

\begin{nb}
    Se un sistema ha una sola soluzione, allora la sua matrice completa avrà un pivot in tutte le colonne tranne per quella corrispondente al vettore dei termini noti.
\end{nb}

\subsection{Infinite soluzioni}
\begin{newdef}{Sistema indeterminato}
    Un sistema $A\textbf{x} = \textbf{b}$ è detto \textbf{indeterminato} se esistono infiniti vettori \textbf{s} che soddisfano il sistema.
\end{newdef}
I sistemi lineari indeterminati hanno un numero di equazioni ``nuove'' (ovvero non derivate da combinazioni di altre equazioni del sistema) più basso del numero di incognite.

Quando si parla di soluzioni di un sistema indeterminato, è importante notare che non si parla di infinite soluzioni casuali: è possibile infatti esprimere in maniera parametrica la ``famiglia'' di vettori che risolve il sistema di equazioni. Nella risoluzione di sistemi lineari indeterminati si avrà, infatti, un insieme di variabili \textit{libere}, ovvero che possono assumere un qualunque valore reale, e un insieme di variabili \textit{vincolate}, ovvero il cui valore è fisso ma determinato dalle variabili libere.

\begin{esempio}
    \textbf{Risolvere il seguente sistema lineare:}
    \[
        \begin{cases}
            x + y - z + 2w = 4 \\
            2x -y + w = 5 \\
            -x + 3y + z = 6 \\
            -x + 10y - z + 5w = 19
        \end{cases}
    \]
    Si scrive la matrice completa del sistema:
    \[
        (A|\textbf{b}) =
        \begin{sqmatrix}{c c c c c}
            1 & 1 & -1 & 2 & 4 \\
            2 & -1 & 0 & 1 & 5 \\
            -1 & 3 & 1 & 0 & 6 \\
            -1 & 10 & -1 & 5 & 19
        \end{sqmatrix}
    \]
    Poi si applica il MEG.
    \begin{center}
        \begin{minipage}{.4\textwidth}
            \[
                \begin{sqmatrix}{c c c c c}
                    1 & 1 & -1 & 2 & 4 \\
                    0 & 3 & -2 & 3 & 3 \\
                    0 & 4 & 0 & 2 & 10 \\
                    0 & 11 & -2 & 7 & 23
                \end{sqmatrix}
            \]
        \end{minipage}
        \begin{minipage}{.4\textwidth}
            \[
                R_2 = 2 \cdot R_1 - R_2
            \]
            \[
                R_3 = R_1 + R_3
            \]
            \[
                R_4 = R_1 + R_4
            \]
        \end{minipage}
    \end{center}
    \begin{center}
        \begin{minipage}{.4\textwidth}
            \[
                \begin{sqmatrix}{c c c c c}
                    1 & 1 & -1 & 2 & 4 \\
                    0 & 3 & -2 & 3 & 3 \\
                    0 & 0 & -8 & 6 & -18 \\
                    0 & 0 & -16 & 12 & -36
                \end{sqmatrix}
            \]
        \end{minipage}
        \begin{minipage}{.4\textwidth}
            \[
                R_3 = 4 \cdot R_2 - 3 \cdot R_3
            \]
            \[
                R_4 = 11 \cdot R_2 - 3 \cdot R_4
            \]
        \end{minipage}
    \end{center}
    \begin{center}
        \begin{minipage}{.4\textwidth}
            \[
                \begin{sqmatrix}{c c c c c}
                    1 & 1 & -1 & 2 & 4 \\
                    0 & 3 & -2 & 3 & 3 \\
                    0 & 0 & -8 & 6 & -18 \\
                    0 & 0 & 0 & 0 & 0
                \end{sqmatrix}
            \]
        \end{minipage}
        \begin{minipage}{.4\textwidth}
            \[
                R_4 = 2 \cdot R_3 - R_4
            \]
        \end{minipage}
    \end{center}
    Come è possibile vedere, le prime tre colonne, corrispondenti a $x$, $y$ e $z$, hanno un pivot: queste saranno le variabili vincolate. Invece la quarta colonna, quella di $w$, non ha alcun pivot: questa è la variabile libera. Passando al sistema lineare associato:
    \[
        \begin{cases}
            x + y - z + 2w = 4 \\
            3y - 2z + 3w = 3 \\
            -8z + 6w = -18 \\
            0 = 0
        \end{cases}
    \]
    A questo punto si trovano $x$, $y$ e $z$ in funzione di $w$.
    \[
        \begin{cases}
            x + y - z + 2w = 4 \\
            3y - 2z + 3w = 3 \\
            8z = 18 + 6w \rightarrow z = \frac{9}{4} + \frac{3}{4}w
        \end{cases}
    \]
    \[
        \begin{cases}
            x + y - z + 2w = 4 \\
            3y - \frac{9}{2} - \frac{3}{2}w + 3w = 3 \rightarrow y = \frac{5}{2} - \frac{1}{2}w \\
            z = \frac{9}{4} + \frac{3}{4}w
        \end{cases}
    \]
    \[
        \begin{cases}
            x + \frac{5}{2} - \frac{1}{2}w - \frac{9}{4} - \frac{3}{4}w + 2w = 4 \rightarrow x = \frac{15}{4} + \frac{3}{4}w\\
            y = \frac{5}{2} - \frac{1}{2}w \\
            z = \frac{9}{4} + \frac{3}{4}w
        \end{cases}
    \]
    \[
        \begin{cases}
            x = \frac{15}{4} + \frac{3}{4}w\\
            y = \frac{5}{2} - \frac{1}{2}w \\
            z = \frac{9}{4} + \frac{3}{4}w
        \end{cases}
    \]
    Il vettore soluzione sarà quindi:
    \[
        \textbf{v} =
        \begin{sqcolvec}
            x \\
            y \\
            z \\
            w
        \end{sqcolvec}
        =
        \begin{sqcolvec}
            \frac{15}{4} + \frac{3}{4}w \\[2pt]
            \frac{5}{2} - \frac{1}{2}w \\[2pt]
            \frac{9}{4} + \frac{3}{4}w \\
            w
        \end{sqcolvec}
        =
        \begin{sqcolvec}
            \frac{15}{4} \\[2pt]
            \tfrac{5}{2} \\[2pt]
            \frac{9}{4} \\
            0
        \end{sqcolvec}
        + w
        \begin{sqcolvec}
            \frac{3}{4} \\[2pt]
            -\frac{1}{2} \\[2pt]
            \frac{3}{4} \\
            1
        \end{sqcolvec}
        , w \in \mathbb{R}
    \]
\end{esempio}

\begin{nb}
    Nella forma a gradini, la matrice dei coefficienti avrà almeno una colonna senza pivot: a quelle colonne corrispondono le variabili libere.
\end{nb}

\subsection{Relazione tra soluzione di un sistema e del sistema omogeneo associato}
Si prendano in considerazione i seguenti sistemi lineari:
\[
    \begin{cases}
        2x + 4y - 3z = 3 \\
        x + 2y + z = 2 \\
        8x + 16y - 22z = 10 \\
    \end{cases}
    \begin{cases}
        2x + 4y - 3z = 0 \\
        x + 2y + z = 0 \\
        8x + 16y - 22z = 0 \\
    \end{cases}
\]

I due sistemi hanno apparentemente la stessa matrice dei coefficienti, ma uno dei due ha dei termini noti non nulli. Avendo la stessa matrice dei coefficienti, l'unica differenza nella forma ridotta delle due matrici sarà l'ultima colonna:
\[
    \begin{sqmatrix}{c c c c}
        1 & 2 & 0 & \frac{9}{5} \\
        0 & 0 & 1 & \frac{1}{5} \\
        0 & 0 & 0 & 0 \\  
    \end{sqmatrix}
    \begin{sqmatrix}{c c c c}
        1 & 2 & 0 & 0 \\
        0 & 0 & 1 & 0 \\
        0 & 0 & 0 & 0 \\  
    \end{sqmatrix}
\]
\[
    \textbf{x}_1 =
    \begin{sqcolvec}
        x \\ y \\ z
    \end{sqcolvec}
    =
    \begin{sqcolvec}
        \frac{9}{5} \\ 0 \\ \frac{1}{5}
    \end{sqcolvec}
    +
    y
    \begin{sqcolvec}
        -2 \\ 1 \\ 0
    \end{sqcolvec}
    \quad
    \textbf{x}_2 =
    \begin{sqcolvec}
        x \\ y \\ z
    \end{sqcolvec}
    =
    y
    \begin{sqcolvec}
        -2 \\ 1 \\ 0
    \end{sqcolvec}
\]
Anche le soluzioni sono molto simili: infatti la soluzione del sistema omogeneo è presente nella soluzione del sistema non omogeneo, benché sommata a un altro vettore.

Quello presentato non è un caso particolare, ma questa relazione tra un sistema e il suo sistema omogeneo associato è valida per qualunque sistema lineare.
\begin{teo}{Soluzione particolare + omogenea}
    Dato il sistema $A\textbf{x} = \textbf{b}$ si può esprimere l'insieme delle sue soluzioni come l'insieme delle soluzioni del sistema omogeneo $A\textbf{x} = \vec 0$ sommato a una soluzione particolare.
    \[
        \text{Sol}\,(A,\textbf{b}) = \textbf{x}_{\text{part}} + \text{Sol}\,(A,\vec 0)
    \]
\end{teo}
\begin{newdim}
    Si considerino $y \in \textbf{Sol}\,(A,\vec 0)$, ovvero $Ay = \vec 0$, e $\textbf{x}_\text{part} \in \textbf{Sol}\,{A,\textbf{b}}$, ovvero $A\textbf{x}_{part} = \textbf{b}$.

    Calcolando il sistema per $\textbf{x}_\text{part} + y$ si ottiene:
    \[
        A(\textbf{x}_\text{part} + y) = A\textbf{x}_\text{part} + Ay = \textbf{b} + \vec 0 = \textbf{b}
    \]
    Quindi la somma con una soluzione del sistema omogeneo continua ad essere soluzione del sistema non omogeneo. Perciò è lecito concludere che, avendo una soluzione del sistema lineare non omogeneo, aggiungere una soluzione del sistema omogeneo mantiene il risultato nell'insieme $\text{Sol}\,(A,\textbf{b})$.

    Si consideri ora $\textbf{x}' \in \textbf{Sol}\,(A,\textbf{b})$. Allora si ha $y = \textbf{x}' - \textbf{x}_\text{part}$. Infatti:
    \[
        Ay = A(\textbf{x}' - \textbf{x}_\text{part}) = A\textbf{x}' - A\textbf{x}_\text{part} = \textbf{b} - \textbf{b} = \vec 0
    \]
    Perciò due soluzioni del sistema non omogeneo differiscono di una soluzione del sistema omogeneo. Perciò:
    \[
        \textbf{x}' = \textbf{x}_\text{part} + y
    \]
    ovvero ogni soluzione può essere espressa come la somma tra una soluzione particolare del sistema non omogeneo e una soluzione del sistema omogeneo, che è esattamente la tesi proposta.
    
    $\hfill\qedwhite$
\end{newdim}